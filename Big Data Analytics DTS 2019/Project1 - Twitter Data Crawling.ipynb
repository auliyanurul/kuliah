{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collecting Project\n",
    "## Studi Kasus: Twitter Data Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# setting key and token\n",
    "consumer_key = \"IGwLpXfcsmEa4T6L7ylTA\"\n",
    "consumer_secret = \"c1qmA10xxV89NlSiJUa3rZmEhJjMWSZbMeqb0uvjf0\"\n",
    "access_token = \"100716381-OtKlDqbhAoHSZOfAsYut6hXuSJxbCpwdUChxjt3g\"\n",
    "access_token_secret = \"zgrSX76bDEkScTVD9qDnolONi4ZF46weJ85jvK53RA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat object authentication ke API Twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# mensetting access token and secret key\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# melakukan authentication ke Twitter API\n",
    "api = tweepy.API(auth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan crawling ke semua data public di home timeline\n",
    "public_tweets = api.home_timeline()\n",
    "\n",
    "for tweets in public_tweets:\n",
    "    print(tweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan crawling 10 data public di home timeline \n",
    "for tweet in tweepy.Cursor(api.home_timeline).items(10):\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan nama-nama friends\n",
    "for friend in tweepy.Cursor(api.friends).items():\n",
    "    print(friend.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengcrawl data tweets kita sendiri\n",
    "for tweet in tweepy.Cursor(api.user_timeline).items():\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengcrawl 5 data tweets dari 'nytimes'\n",
    "for tweet in api.user_timeline(id=\"nytimes\", count=5):\n",
    "   print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# menampilkan 5 data hasil crawling detikcom ke dalam format JSON\n",
    "for tweet in api.user_timeline(id=\"detikcom\", count=1):\n",
    "    print(json.dumps(tweet._json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil tweets dengan taggar tertentu dg search\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#bigdata\",\n",
    "                           lang=\"en\",\n",
    "                           since=\"2019-01-01\").items(1):\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil item tertentu dari JSON tweets ke list\n",
    "tweets_data = []\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#bigdata\",\n",
    "                           lang=\"en\",\n",
    "                           since=\"2019-01-01\").items(5):\n",
    "    tweets_data.append([tweet.author.screen_name,\n",
    "                        tweet.lang,\n",
    "                        tweet.created_at,\n",
    "                        tweet.favorite_count,\n",
    "                        tweet.retweet_count,\n",
    "                        tweet.text])\n",
    "print(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to Dataframe\n",
    "import pandas as pd\n",
    "tweets_pd = pd.DataFrame(tweets_data,\n",
    "                         columns=['screen_name', 'lang', 'created_at', 'fav_count', 'retweet_count', 'text'])\n",
    "display(tweets_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengkonversi dataframe ke file csv\n",
    "bytes_to_write = tweets_pd.to_csv(index = None, header=True).encode()\n",
    "\n",
    "# letakkan file csv ke bucket S3\n",
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "with s3.open('rosihanari/data_twitter.csv', 'wb') as f:\n",
    "    f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    \n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "\n",
    "    def on_status(self, status):\n",
    "        \n",
    "        # membatasi jumlah data streaming tweets (n = 5)\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 5:\n",
    "            # mencetak data hasil streaming\n",
    "            print(status.text)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)\n",
    "\n",
    "# streaming keyword='python'\n",
    "myStream.filter(track=['python'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lakukan data collecting terhadap Twitter melalui streaming dengan ketentuan sbb:\n",
    "- Streaming dilakukan pada taggar **#BigData**. \n",
    "- Jumlah data yang dicollect sebanyak 50 buah. \n",
    "- Data yang dicollect adalah '**screen_name**', '**lang**', '**created_at**', '**retweet_count**', '**text**', '**location**'\n",
    "- Tampung data hasil streaming ke dalam list\n",
    "- Konversikan data list hasil streaming ke dalam dataframe\n",
    "- Simpan dataframe hasil streaming ke dalam Amazon S3 dalam format CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
